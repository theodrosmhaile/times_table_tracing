## TafelTrainer Data Analysis

```{r setup, include=FALSE}
# Load required libraries
library(skimr)
library(tidyverse)
library(lubridate)
library(anytime)
```

### Description

This analysis prepares data from Levels 1, 2, and 3 of the TafelTrainer dataset. The goal is to create datasets for GraafTel input (first, middle, and last encounters) and conduct descriptive analyses.

### Data Preparation

```{r}
# Load dataset
dat <- readRDS('./TafelTrainer pilot data/tt_responses_all_clean.rds')

# Initial filtering: Ensure 'correct' is numeric and clean `cue_text`
dat <- dat %>%
  mutate(
    correct = as.numeric(correct),
    cue_text = str_replace_all(cue_text, "\\+", " ") # Replace "+" with a space
  )

# Define valid responses (numeric values â‰¤ 100)
valid_responses <- 0:100

# Filter for valid 'given_response'
dat <- dat %>%
  filter(as.numeric(given_response) %in% valid_responses)

# Add multiplier and multiplicand columns globally to the dataset
dat <- dat %>%
  mutate(
    multiplier = as.numeric(str_extract(cue_text, "^\\d+")), # Extract the first number in `cue_text`
    multiplicand = as.numeric(str_extract(cue_text, "\\d+$")) # Extract the second number in `cue_text`
  )

# Function to process each level and add encounter counter
prepare_level_data <- function(data, level_filter) {
  data %>%
    filter(level == level_filter) %>%
    arrange(user_id, cue_text, session_id) %>%
    group_by(user_id, cue_text) %>%
    mutate(encounter_num = row_number()) %>%
    ungroup()
}

# Prepare full datasets for Levels 1, 2, and 3 (including `encounter_num`)
dat_level1 <- prepare_level_data(dat, 1)
dat_level2 <- prepare_level_data(dat, 2)
dat_level3 <- prepare_level_data(dat, 3)

# Function to filter specific encounters dynamically
filter_encounter <- function(data, encounter_type) {
  data %>%
    group_by(user_id, cue_text) %>%
    filter(
      case_when(
        # First encounter
        encounter_type == "first" ~ encounter_num == 1,
        # Middle encounter: Use ceiling(n() / 2), but if it results in 1, use 2 if available
        encounter_type == "middle" ~ {
          middle_encounter <- ceiling(n() / 2)
          encounter_num == if_else(middle_encounter == 1 & n() > 1, 2L, middle_encounter)
        },
        # Last encounter
        encounter_type == "last" ~ encounter_num == n(),
        # Default: Exclude rows
        TRUE ~ FALSE
      )
    ) %>%
    ungroup()
}

# Generate encounter-specific datasets dynamically from the full datasets
dat_level1_first <- filter_encounter(dat_level1, "first")
dat_level1_middle <- filter_encounter(dat_level1, "middle")
dat_level1_last <- filter_encounter(dat_level1, "last")

dat_level2_first <- filter_encounter(dat_level2, "first")
dat_level2_middle <- filter_encounter(dat_level2, "middle")
dat_level2_last <- filter_encounter(dat_level2, "last")

dat_level3_first <- filter_encounter(dat_level3, "first")
dat_level3_middle <- filter_encounter(dat_level3, "middle")
dat_level3_last <- filter_encounter(dat_level3, "last")
```

### Export Data for GraafTel

```{r}
# Function to export datasets
export_graaftel_data <- function(data, level, encounter_type) {
  # Construct the filename
  file_name <- paste0("./graaftel_input_level", level, "_", encounter_type, ".csv")
  # Select the required columns
  data_to_export <- data %>%
    select(user_id, cue_text, correct)
  # Write data to CSV (without column headers)
  write.table(data_to_export, file_name, row.names = FALSE, col.names = FALSE, sep = ",")
}

# Export data for Level 1
export_graaftel_data(dat_level1_first, 1, "first")
export_graaftel_data(dat_level1_middle, 1, "middle")
export_graaftel_data(dat_level1_last, 1, "last")

# Export data for Level 2
export_graaftel_data(dat_level2_first, 2, "first")
export_graaftel_data(dat_level2_middle, 2, "middle")
export_graaftel_data(dat_level2_last, 2, "last")

# Export data for Level 3
export_graaftel_data(dat_level3_first, 3, "first")
export_graaftel_data(dat_level3_middle, 3, "middle")
export_graaftel_data(dat_level3_last, 3, "last")
```

### Verify Outputs

```{r}
# Prepare data for verification
# Combine all levels and encounter types to verify overall distribution
verify_data <- bind_rows(
  dat_level1 %>% mutate(level == 1),
  dat_level2 %>% mutate(level == 2),
  dat_level3 %>% mutate(level == 3)
)

# Plot histogram for the distribution of responses
# Ensures that the data used for GraafTel matches expected values
verify_data %>%
  select(given_response, cue_text, level) %>%
  filter(given_response %in% 0:100) %>%
  mutate(given_response = as.numeric(given_response)) %>%
  ggplot(aes(x = given_response, fill = factor(level))) +
  geom_histogram(binwidth = 1, position = "dodge") +
  theme_minimal() +
  labs(
    title = "Distribution of Responses Across Levels",
    x = "Given Response",
    y = "Count",
    fill = "Level"
  ) +
  theme(axis.text.x = element_text(angle = 90)) +
  scale_fill_brewer(palette = "Set3")

# Calculate mean accuracy for each fact_id and level
mean_accuracy_data <- verify_data %>%
  group_by(level, cue_text) %>% # Group by level and fact_id
  summarize(mean_accuracy = mean(correct), .groups = "drop") # Calculate mean accuracy

# Create a box plot of mean accuracies
mean_accuracy_data %>%
  ggplot(aes(x = factor(level), y = mean_accuracy, fill = factor(level))) +
  geom_boxplot(alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of Mean Accuracies by Level",
    x = "Level",
    y = "Mean Accuracy",
    fill = "Level"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme(legend.position = "none")
```

### Descriptive Statistics

```{r}
generate_descriptive_data <- function(data) {
  # Group by cue_text and compute summary statistics
  data %>%
    select(given_response, cue_text, correct, level, fact_id) %>%
    mutate(cue_text=fct_reorder(cue_text,fact_id)) %>% 
    group_by(cue_text) %>%
    summarise(mean_acc = mean(correct), n=n(), se = sd(correct)/sqrt(n)
    ) %>%
    mutate(
      multiplier = as.numeric(str_extract(cue_text, "^\\d+")), # Extract the first number in `cue_text`
      multiplicand = as.numeric(str_extract(cue_text, "\\d+$")) # Extract the second number in `cue_text`
    ) %>%
    mutate(cue_text=fct_reorder(cue_text,multiplicand))
}


# Generate descriptive data
dat4plot_level1 <- generate_descriptive_data(dat_level1)
dat4plot_level1_first <- generate_descriptive_data(dat_level1_first)
dat4plot_level1_middle <- generate_descriptive_data(dat_level1_middle)
dat4plot_level1_last <- generate_descriptive_data(dat_level1_last)
dat4plot_level2 <- generate_descriptive_data(dat_level2)
dat4plot_level2_first <- generate_descriptive_data(dat_level2_first)
dat4plot_level2_middle <- generate_descriptive_data(dat_level2_middle)
dat4plot_level2_last <- generate_descriptive_data(dat_level2_last)
dat4plot_level3 <- generate_descriptive_data(dat_level3)
dat4plot_level3_first <- generate_descriptive_data(dat_level3_first)
dat4plot_level3_middle <- generate_descriptive_data(dat_level3_middle)
dat4plot_level3_last <- generate_descriptive_data(dat_level3_last)


# Function to plot heatmaps with properly ordered and labeled axes
plot_heatmap <- function(data, title) {
  # Update multiplier to numeric for proper ordering and labeling
  data <- data %>%
    mutate(multiplier = as.numeric(gsub("col", "", multiplier)))

  data %>%
    ggplot(aes(x = as.factor(multiplier), y = as.factor(multiplicand), fill = mean_acc, label = round(mean_acc, 2))) +
    geom_tile() +
    geom_text(size = 3) + # Adjust text size for readability
    scale_fill_gradient2(
      limits = c(0.7, 1),
      midpoint = 0.85,
      low = 'blue',
      mid = "red",
      high = 'yellow',
      guide = 'colorbar',
      aesthetics = 'fill',
      breaks = seq(0.7, 1, by = 0.05) # Reduce the number of breaks for readability
    ) +
    theme_minimal() +
    labs(
      title = title,
      x = "Multiplier",
      y = "Multiplicand",
      fill = "Mean Accuracy"
    ) +
    theme(
      axis.text.x = element_text(angle = 0), # Ensure x-axis labels are horizontal
      axis.text.y = element_text(angle = 0), # Ensure y-axis labels are clear
      legend.key.height = unit(0.5, "cm") # Adjust legend key size for readability
    )
}

# Function to plot bar plots with error bars
plot_barplot <- function(data, title) {
  data %>%
    ggplot(aes(
      x = cue_text, y = mean_acc, ymax = mean_acc + se, ymin = mean_acc - se, fill = as.factor(multiplicand)
    )) +
    geom_bar(stat = 'identity') +
    geom_errorbar() +
    scale_x_discrete(
      breaks = levels(data$cue_text)[seq(1, length(levels(data$cue_text)), by = 10)] # Show every 10th label correctly
    ) +
    theme_minimal() +
    labs(
      title = title,
      x = "Cue Text (Multiplication Fact)",
      y = "Mean Accuracy",
      fill = "Multiplicand"
    ) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = 'top')
}

# Generate plots for each level and overall
# Heatmaps
heatmap_level1 <- plot_heatmap(dat4plot_level1, "Heatmap of Mean Accuracy (Level 1: Overall)")
heatmap_level1_first <- plot_heatmap(dat4plot_level1_first, "Heatmap of Mean Accuracy (Level 1: First)")
heatmap_level1_middle <- plot_heatmap(dat4plot_level1_middle, "Heatmap of Mean Accuracy (Level 1: Middle)")
heatmap_level1_last <- plot_heatmap(dat4plot_level1_last, "Heatmap of Mean Accuracy (Level 1: Last)")
heatmap_level2 <- plot_heatmap(dat4plot_level2, "Heatmap of Mean Accuracy (Level 2: Overall)")
heatmap_level2_first <- plot_heatmap(dat4plot_level2_first, "Heatmap of Mean Accuracy (Level 2: First)")
heatmap_level2_middle <- plot_heatmap(dat4plot_level2_middle, "Heatmap of Mean Accuracy (Level 2: Middle)")
heatmap_level2_last <- plot_heatmap(dat4plot_level2_last, "Heatmap of Mean Accuracy (Level 2: Last)")
heatmap_level3 <- plot_heatmap(dat4plot_level3, "Heatmap of Mean Accuracy (Level 3: Overall)")
heatmap_level3_first <- plot_heatmap(dat4plot_level3_first, "Heatmap of Mean Accuracy (Level 3: First)")
heatmap_level3_middle <- plot_heatmap(dat4plot_level3_middle, "Heatmap of Mean Accuracy (Level 3: Middle)")
heatmap_level3_last <- plot_heatmap(dat4plot_level3_last, "Heatmap of Mean Accuracy (Level 3: Last)")

# Bar Plots
barplot_level1 <- plot_barplot(dat4plot_level1, "Bar Plot of Mean Accuracy (Level 1: Overall)")
barplot_level1_first <- plot_barplot(dat4plot_level1_first, "Bar Plot of Mean Accuracy (Level 1: First)")
barplot_level1_middle <- plot_barplot(dat4plot_level1_middle, "Bar Plot of Mean Accuracy (Level 1: Middle)")
barplot_level1_last <- plot_barplot(dat4plot_level1_last, "Bar Plot of Mean Accuracy (Level 1: Last)")
barplot_level2 <- plot_barplot(dat4plot_level2, "Bar Plot of Mean Accuracy (Level 2: Overall)")
barplot_level2_first <- plot_barplot(dat4plot_level2_first, "Bar Plot of Mean Accuracy (Level 2: First)")
barplot_level2_middle <- plot_barplot(dat4plot_level2_middle, "Bar Plot of Mean Accuracy (Level 2: Middle)")
barplot_level2_last <- plot_barplot(dat4plot_level2_last, "Bar Plot of Mean Accuracy (Level 2: Last)")
barplot_level3 <- plot_barplot(dat4plot_level3, "Bar Plot of Mean Accuracy (Level 3: Overall)")
barplot_level3_first <- plot_barplot(dat4plot_level3_first, "Bar Plot of Mean Accuracy (Level 3: First)")
barplot_level3_middle <- plot_barplot(dat4plot_level3_middle, "Bar Plot of Mean Accuracy (Level 3: Middle)")
barplot_level3_last <- plot_barplot(dat4plot_level3_last, "Bar Plot of Mean Accuracy (Level 3: Last)")

# Display plots
heatmap_level1
heatmap_level1_first
heatmap_level1_middle
heatmap_level1_last
heatmap_level2
heatmap_level2_first
heatmap_level2_middle
heatmap_level2_last
heatmap_level3
heatmap_level3_first
heatmap_level3_middle
heatmap_level3_last

barplot_level1
barplot_level1_first
barplot_level1_middle
barplot_level1_last
barplot_level2
barplot_level2_first
barplot_level2_middle
barplot_level2_last
barplot_level3
barplot_level3_first
barplot_level3_middle
barplot_level3_last
```

### GraafTel Data Export Analysis
```{r}
# Create mean accuracy datasets for each level
mean_accuracy_level1 <- verify_data %>%
  filter(level == 1) %>% # Filter for Level 1 data only
  group_by(cue_text) %>% # Group by cue_text
  summarise(mean_accuracy = mean(correct), .groups = "drop") # Calculate mean accuracy

mean_accuracy_level2 <- verify_data %>%
  filter(level == 2) %>% # Filter for Level 2 data only
  group_by(cue_text) %>% # Group by cue_text
  summarise(mean_accuracy = mean(correct), .groups = "drop") # Calculate mean accuracy

mean_accuracy_level3 <- verify_data %>%
  filter(level == 3) %>% # Filter for Level 3 data only
  group_by(cue_text) %>% # Group by cue_text
  summarise(mean_accuracy = mean(correct), .groups = "drop") # Calculate mean accuracy

```

```{r}
# Function to calculate mean accuracy from preprocessed datasets
calculate_mean_accuracy <- function(data) {
  data %>%
    group_by(cue_text) %>% # Group by cue_text
    summarise(mean_accuracy = mean(correct), .groups = "drop") # Calculate mean accuracy
}

# Generate mean accuracy datasets for Level 1
mean_accuracy_level1_first <- calculate_mean_accuracy(dat_level1_first)
mean_accuracy_level1_middle <- calculate_mean_accuracy(dat_level1_middle)
mean_accuracy_level1_last <- calculate_mean_accuracy(dat_level1_last)

# Generate mean accuracy datasets for Level 2
mean_accuracy_level2_first <- calculate_mean_accuracy(dat_level2_first)
mean_accuracy_level2_middle <- calculate_mean_accuracy(dat_level2_middle)
mean_accuracy_level2_last <- calculate_mean_accuracy(dat_level2_last)

# Generate mean accuracy datasets for Level 3
mean_accuracy_level3_first <- calculate_mean_accuracy(dat_level3_first)
mean_accuracy_level3_middle <- calculate_mean_accuracy(dat_level3_middle)
mean_accuracy_level3_last <- calculate_mean_accuracy(dat_level3_last)
```

```{r}
# Function to filter and clean GraafTel output
filter_graaftel_data <- function(file_path) {
  graaftel_data <- read_csv(file_path, col_names = FALSE, col_types = cols(
    X1 = col_character(),
    X2 = col_character(),
    X3 = col_double(),
    X4 = col_double(),
    X5 = col_double()
  ))

  # Rename columns for clarity
  colnames(graaftel_data) <- c("item", "cue_text", "skill1", "skill2", "skill3")

  # Filter out rows containing "student" in the first column
  graaftel_data <- graaftel_data %>%
    filter(!str_detect(item, "student")) %>%
    select(-item)

  # Remove any leading spaces in cue_text
  graaftel_data <- graaftel_data %>%
    mutate(cue_text = str_trim(cue_text, side = "both"))

  return(graaftel_data)
}

# List of file paths for all GraafTel outputs
file_paths <- list.files(
  path = "./GT_ratings",
  pattern = "l[1-3]_(first|middle|last)_3sk.csv",
  full.names = TRUE
)

# Apply the filtering function to all files
filtered_graaftel_data <- lapply(file_paths, filter_graaftel_data)

# Name the datasets based on file names without extensions
names(filtered_graaftel_data) <- gsub(".*/|\\.csv$", "", file_paths)

# Assign cleaned datasets to individual variables for the 9 cases
l1_first_3sk <- filtered_graaftel_data[["l1_first_3sk"]]
l1_middle_3sk <- filtered_graaftel_data[["l1_middle_3sk"]]
l1_last_3sk <- filtered_graaftel_data[["l1_last_3sk"]]

l2_first_3sk <- filtered_graaftel_data[["l2_first_3sk"]]
l2_middle_3sk <- filtered_graaftel_data[["l2_middle_3sk"]]
l2_last_3sk <- filtered_graaftel_data[["l2_last_3sk"]]

l3_first_3sk <- filtered_graaftel_data[["l3_first_3sk"]]
l3_middle_3sk <- filtered_graaftel_data[["l3_middle_3sk"]]
l3_last_3sk <- filtered_graaftel_data[["l3_last_3sk"]]
```

```{r}
# Function to calculate correlations for all encounters in a level
calculate_all_correlations <- function(level, mean_accuracy_first, mean_accuracy_middle, mean_accuracy_last) {
  list(
    first = calculate_skill_correlations(level$first, mean_accuracy_first),
    middle = calculate_skill_correlations(level$middle, mean_accuracy_middle),
    last = calculate_skill_correlations(level$last, mean_accuracy_last)
  ) %>%
    bind_rows(.id = "encounter")
}

# Combine data from all levels and encounters
combine_correlation_data <- function(levels) {
  map_dfr(levels, ~ calculate_all_correlations(.x, .x$mean_accuracy_first, .x$mean_accuracy_middle, .x$mean_accuracy_last),
          .id = "level")
}

# Data setup for each level (replace these with your datasets)
level1 <- list(
  first = l1_first_3sk,
  middle = l1_middle_3sk,
  last = l1_last_3sk,
  mean_accuracy_first = mean_accuracy_level1_first,
  mean_accuracy_middle = mean_accuracy_level1_middle,
  mean_accuracy_last = mean_accuracy_level1_last
)

level2 <- list(
  first = l2_first_3sk,
  middle = l2_middle_3sk,
  last = l2_last_3sk,
  mean_accuracy_first = mean_accuracy_level2_first,
  mean_accuracy_middle = mean_accuracy_level2_middle,
  mean_accuracy_last = mean_accuracy_level2_last
)

level3 <- list(
  first = l3_first_3sk,
  middle = l3_middle_3sk,
  last = l3_last_3sk,
  mean_accuracy_first = mean_accuracy_level3_first,
  mean_accuracy_middle = mean_accuracy_level3_middle,
  mean_accuracy_last = mean_accuracy_level3_last
)

# Calculate correlations for all levels
all_correlations <- combine_correlation_data(list(level1, level2, level3))

# Plot correlations using a facet grid
ggplot(all_correlations, aes(x = skill, y = pearsons_r, fill = skill)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  facet_grid(level ~ encounter) +
  theme_minimal() +
  labs(
    title = "Correlations Between Skill Probabilities and Mean Accuracy",
    x = "Skill",
    y = "Pearson's r"
  ) +
  scale_fill_brewer(palette = "Set3")
```
